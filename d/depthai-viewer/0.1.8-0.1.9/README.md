# Comparing `tmp/depthai_viewer-0.1.8-cp38-abi3-win_amd64.whl.zip` & `tmp/depthai_viewer-0.1.9-cp38-abi3-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,71 +1,71 @@
-Zip file size: 9886334 bytes, number of entries: 69
--rw-rw-rw-  2.0 fat    17989 b- defN 24-Mar-01 21:27 depthai_viewer/__init__.py
--rw-rw-rw-  2.0 fat      953 b- defN 24-Mar-01 21:27 depthai_viewer/__main__.py
--rw-rw-rw-  2.0 fat     2956 b- defN 24-Mar-01 21:27 depthai_viewer/color_conversion.py
--rw-rw-rw-  2.0 fat     5673 b- defN 24-Mar-01 21:27 depthai_viewer/install_requirements.py
--rw-rw-rw-  2.0 fat        0 b- defN 24-Mar-01 21:27 depthai_viewer/py.typed
--rw-rw-rw-  2.0 fat     5016 b- defN 24-Mar-01 21:27 depthai_viewer/recording.py
--rw-rw-rw-  2.0 fat      339 b- defN 24-Mar-01 21:27 depthai_viewer/requirements.txt
--rw-rw-rw-  2.0 fat     2666 b- defN 24-Mar-01 21:27 depthai_viewer/script_helpers.py
--rw-rw-rw-  2.0 fat       61 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/.gitignore
--rw-rw-rw-  2.0 fat      992 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/README.md
--rw-rw-rw-  2.0 fat        0 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/__init__.py
--rw-rw-rw-  2.0 fat      336 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/classification_labels.py
--rw-rw-rw-  2.0 fat     7264 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/config_api.py
--rw-rw-rw-  2.0 fat     3367 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/depth.py
--rw-rw-rw-  2.0 fat    31193 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/device.py
--rw-rw-rw-  2.0 fat    13442 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/device_configuration.py
--rw-rw-rw-  2.0 fat     8313 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/main.py
--rw-rw-rw-  2.0 fat     3726 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/messages.py
--rw-rw-rw-  2.0 fat    13036 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/packet_handler.py
--rw-rw-rw-  2.0 fat        0 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/py.typed
--rw-rw-rw-  2.0 fat     1778 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/store.py
--rw-rw-rw-  2.0 fat      609 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/topic.py
--rw-rw-rw-  2.0 fat      959 b- defN 24-Mar-01 21:27 depthai_viewer/_backend/device_defaults/oak_t_default.py
--rw-rw-rw-  2.0 fat     2884 b- defN 24-Mar-01 21:27 depthai_viewer/components/__init__.py
--rw-rw-rw-  2.0 fat     1614 b- defN 24-Mar-01 21:27 depthai_viewer/components/annotation.py
--rw-rw-rw-  2.0 fat     1243 b- defN 24-Mar-01 21:27 depthai_viewer/components/arrow.py
--rw-rw-rw-  2.0 fat      925 b- defN 24-Mar-01 21:27 depthai_viewer/components/box.py
--rw-rw-rw-  2.0 fat      980 b- defN 24-Mar-01 21:27 depthai_viewer/components/color.py
--rw-rw-rw-  2.0 fat     1600 b- defN 24-Mar-01 21:27 depthai_viewer/components/imu.py
--rw-rw-rw-  2.0 fat     1100 b- defN 24-Mar-01 21:27 depthai_viewer/components/instance.py
--rw-rw-rw-  2.0 fat      821 b- defN 24-Mar-01 21:27 depthai_viewer/components/label.py
--rw-rw-rw-  2.0 fat     2515 b- defN 24-Mar-01 21:27 depthai_viewer/components/linestrip.py
--rw-rw-rw-  2.0 fat     1958 b- defN 24-Mar-01 21:27 depthai_viewer/components/point.py
--rw-rw-rw-  2.0 fat      990 b- defN 24-Mar-01 21:27 depthai_viewer/components/quaternion.py
--rw-rw-rw-  2.0 fat      863 b- defN 24-Mar-01 21:27 depthai_viewer/components/radius.py
--rw-rw-rw-  2.0 fat     1856 b- defN 24-Mar-01 21:27 depthai_viewer/components/rect2d.py
--rw-rw-rw-  2.0 fat     1692 b- defN 24-Mar-01 21:27 depthai_viewer/components/scalar.py
--rw-rw-rw-  2.0 fat     4374 b- defN 24-Mar-01 21:27 depthai_viewer/components/tensor.py
--rw-rw-rw-  2.0 fat     1132 b- defN 24-Mar-01 21:27 depthai_viewer/components/text_entry.py
--rw-rw-rw-  2.0 fat     1634 b- defN 24-Mar-01 21:27 depthai_viewer/components/vec.py
--rw-rw-rw-  2.0 fat      902 b- defN 24-Mar-01 21:27 depthai_viewer/components/xlink_stats.py
--rw-rw-rw-  2.0 fat     3459 b- defN 24-Mar-01 21:27 depthai_viewer/log/__init__.py
--rw-rw-rw-  2.0 fat     5681 b- defN 24-Mar-01 21:27 depthai_viewer/log/annotation.py
--rw-rw-rw-  2.0 fat     3268 b- defN 24-Mar-01 21:27 depthai_viewer/log/arrow.py
--rw-rw-rw-  2.0 fat     4431 b- defN 24-Mar-01 21:27 depthai_viewer/log/bounding_box.py
--rw-rw-rw-  2.0 fat     1946 b- defN 24-Mar-01 21:27 depthai_viewer/log/camera.py
--rw-rw-rw-  2.0 fat     1100 b- defN 24-Mar-01 21:27 depthai_viewer/log/error_utils.py
--rw-rw-rw-  2.0 fat     4879 b- defN 24-Mar-01 21:27 depthai_viewer/log/extension_components.py
--rw-rw-rw-  2.0 fat     3198 b- defN 24-Mar-01 21:27 depthai_viewer/log/file.py
--rw-rw-rw-  2.0 fat     8154 b- defN 24-Mar-01 21:27 depthai_viewer/log/image.py
--rw-rw-rw-  2.0 fat     1857 b- defN 24-Mar-01 21:27 depthai_viewer/log/imu.py
--rw-rw-rw-  2.0 fat     6761 b- defN 24-Mar-01 21:27 depthai_viewer/log/lines.py
--rw-rw-rw-  2.0 fat     1363 b- defN 24-Mar-01 21:27 depthai_viewer/log/log_decorator.py
--rw-rw-rw-  2.0 fat     5439 b- defN 24-Mar-01 21:27 depthai_viewer/log/mesh.py
--rw-rw-rw-  2.0 fat     2060 b- defN 24-Mar-01 21:27 depthai_viewer/log/pipeline_graph.py
--rw-rw-rw-  2.0 fat     9755 b- defN 24-Mar-01 21:27 depthai_viewer/log/points.py
--rw-rw-rw-  2.0 fat     7167 b- defN 24-Mar-01 21:27 depthai_viewer/log/rects.py
--rw-rw-rw-  2.0 fat     5835 b- defN 24-Mar-01 21:27 depthai_viewer/log/scalar.py
--rw-rw-rw-  2.0 fat     4389 b- defN 24-Mar-01 21:27 depthai_viewer/log/tensor.py
--rw-rw-rw-  2.0 fat     4354 b- defN 24-Mar-01 21:27 depthai_viewer/log/text.py
--rw-rw-rw-  2.0 fat     3056 b- defN 24-Mar-01 21:27 depthai_viewer/log/text_internal.py
--rw-rw-rw-  2.0 fat     5980 b- defN 24-Mar-01 21:27 depthai_viewer/log/transform.py
--rw-rw-rw-  2.0 fat      910 b- defN 24-Mar-01 21:27 depthai_viewer/log/xlink_stats.py
--rw-rw-rw-  2.0 fat      175 b- defN 24-Mar-01 21:27 depthai_viewer_bindings/__init__.py
--rw-rw-rw-  2.0 fat 24456192 b- defN 24-Mar-01 21:27 depthai_viewer_bindings/depthai_viewer_bindings.pyd
--rw-rw-rw-  2.0 fat     1527 b- defN 24-Mar-01 21:27 depthai_viewer-0.1.8.dist-info/METADATA
--rw-rw-rw-  2.0 fat       96 b- defN 24-Mar-01 21:27 depthai_viewer-0.1.8.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       62 b- defN 24-Mar-01 21:27 depthai_viewer-0.1.8.dist-info/entry_points.txt
-?rw-rw-r--  2.0 fat     6203 b- defN 24-Mar-01 21:27 depthai_viewer-0.1.8.dist-info/RECORD
-69 files, 24709048 bytes uncompressed, 9876378 bytes compressed:  60.0%
+Zip file size: 9834115 bytes, number of entries: 69
+-rw-rw-rw-  2.0 fat    17989 b- defN 24-Apr-27 20:00 depthai_viewer/__init__.py
+-rw-rw-rw-  2.0 fat      953 b- defN 24-Apr-27 20:00 depthai_viewer/__main__.py
+-rw-rw-rw-  2.0 fat     2956 b- defN 24-Apr-27 20:00 depthai_viewer/color_conversion.py
+-rw-rw-rw-  2.0 fat     5689 b- defN 24-Apr-27 20:00 depthai_viewer/install_requirements.py
+-rw-rw-rw-  2.0 fat        0 b- defN 24-Apr-27 20:00 depthai_viewer/py.typed
+-rw-rw-rw-  2.0 fat     5016 b- defN 24-Apr-27 20:00 depthai_viewer/recording.py
+-rw-rw-rw-  2.0 fat      339 b- defN 24-Apr-27 20:00 depthai_viewer/requirements.txt
+-rw-rw-rw-  2.0 fat     2666 b- defN 24-Apr-27 20:00 depthai_viewer/script_helpers.py
+-rw-rw-rw-  2.0 fat       61 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/.gitignore
+-rw-rw-rw-  2.0 fat      992 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/README.md
+-rw-rw-rw-  2.0 fat        0 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/__init__.py
+-rw-rw-rw-  2.0 fat      336 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/classification_labels.py
+-rw-rw-rw-  2.0 fat     8205 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/config_api.py
+-rw-rw-rw-  2.0 fat     3367 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/depth.py
+-rw-rw-rw-  2.0 fat    31842 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/device.py
+-rw-rw-rw-  2.0 fat    15958 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/device_configuration.py
+-rw-rw-rw-  2.0 fat     8929 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/main.py
+-rw-rw-rw-  2.0 fat     3781 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/messages.py
+-rw-rw-rw-  2.0 fat    13536 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/packet_handler.py
+-rw-rw-rw-  2.0 fat        0 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/py.typed
+-rw-rw-rw-  2.0 fat     1778 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/store.py
+-rw-rw-rw-  2.0 fat      609 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/topic.py
+-rw-rw-rw-  2.0 fat      959 b- defN 24-Apr-27 20:00 depthai_viewer/_backend/device_defaults/oak_t_default.py
+-rw-rw-rw-  2.0 fat     2884 b- defN 24-Apr-27 20:00 depthai_viewer/components/__init__.py
+-rw-rw-rw-  2.0 fat     1614 b- defN 24-Apr-27 20:00 depthai_viewer/components/annotation.py
+-rw-rw-rw-  2.0 fat     1243 b- defN 24-Apr-27 20:00 depthai_viewer/components/arrow.py
+-rw-rw-rw-  2.0 fat      925 b- defN 24-Apr-27 20:00 depthai_viewer/components/box.py
+-rw-rw-rw-  2.0 fat      980 b- defN 24-Apr-27 20:00 depthai_viewer/components/color.py
+-rw-rw-rw-  2.0 fat     1600 b- defN 24-Apr-27 20:00 depthai_viewer/components/imu.py
+-rw-rw-rw-  2.0 fat     1100 b- defN 24-Apr-27 20:00 depthai_viewer/components/instance.py
+-rw-rw-rw-  2.0 fat      821 b- defN 24-Apr-27 20:00 depthai_viewer/components/label.py
+-rw-rw-rw-  2.0 fat     2515 b- defN 24-Apr-27 20:00 depthai_viewer/components/linestrip.py
+-rw-rw-rw-  2.0 fat     1958 b- defN 24-Apr-27 20:00 depthai_viewer/components/point.py
+-rw-rw-rw-  2.0 fat      990 b- defN 24-Apr-27 20:00 depthai_viewer/components/quaternion.py
+-rw-rw-rw-  2.0 fat      863 b- defN 24-Apr-27 20:00 depthai_viewer/components/radius.py
+-rw-rw-rw-  2.0 fat     1856 b- defN 24-Apr-27 20:00 depthai_viewer/components/rect2d.py
+-rw-rw-rw-  2.0 fat     1692 b- defN 24-Apr-27 20:00 depthai_viewer/components/scalar.py
+-rw-rw-rw-  2.0 fat     4374 b- defN 24-Apr-27 20:00 depthai_viewer/components/tensor.py
+-rw-rw-rw-  2.0 fat     1132 b- defN 24-Apr-27 20:00 depthai_viewer/components/text_entry.py
+-rw-rw-rw-  2.0 fat     1634 b- defN 24-Apr-27 20:00 depthai_viewer/components/vec.py
+-rw-rw-rw-  2.0 fat      902 b- defN 24-Apr-27 20:00 depthai_viewer/components/xlink_stats.py
+-rw-rw-rw-  2.0 fat     3459 b- defN 24-Apr-27 20:00 depthai_viewer/log/__init__.py
+-rw-rw-rw-  2.0 fat     5681 b- defN 24-Apr-27 20:00 depthai_viewer/log/annotation.py
+-rw-rw-rw-  2.0 fat     3268 b- defN 24-Apr-27 20:00 depthai_viewer/log/arrow.py
+-rw-rw-rw-  2.0 fat     4431 b- defN 24-Apr-27 20:00 depthai_viewer/log/bounding_box.py
+-rw-rw-rw-  2.0 fat     1946 b- defN 24-Apr-27 20:00 depthai_viewer/log/camera.py
+-rw-rw-rw-  2.0 fat     1100 b- defN 24-Apr-27 20:00 depthai_viewer/log/error_utils.py
+-rw-rw-rw-  2.0 fat     4879 b- defN 24-Apr-27 20:00 depthai_viewer/log/extension_components.py
+-rw-rw-rw-  2.0 fat     3198 b- defN 24-Apr-27 20:00 depthai_viewer/log/file.py
+-rw-rw-rw-  2.0 fat     8154 b- defN 24-Apr-27 20:00 depthai_viewer/log/image.py
+-rw-rw-rw-  2.0 fat     1857 b- defN 24-Apr-27 20:00 depthai_viewer/log/imu.py
+-rw-rw-rw-  2.0 fat     6761 b- defN 24-Apr-27 20:00 depthai_viewer/log/lines.py
+-rw-rw-rw-  2.0 fat     1363 b- defN 24-Apr-27 20:00 depthai_viewer/log/log_decorator.py
+-rw-rw-rw-  2.0 fat     5439 b- defN 24-Apr-27 20:00 depthai_viewer/log/mesh.py
+-rw-rw-rw-  2.0 fat     2060 b- defN 24-Apr-27 20:00 depthai_viewer/log/pipeline_graph.py
+-rw-rw-rw-  2.0 fat     9755 b- defN 24-Apr-27 20:00 depthai_viewer/log/points.py
+-rw-rw-rw-  2.0 fat     7167 b- defN 24-Apr-27 20:00 depthai_viewer/log/rects.py
+-rw-rw-rw-  2.0 fat     5835 b- defN 24-Apr-27 20:00 depthai_viewer/log/scalar.py
+-rw-rw-rw-  2.0 fat     4389 b- defN 24-Apr-27 20:00 depthai_viewer/log/tensor.py
+-rw-rw-rw-  2.0 fat     4354 b- defN 24-Apr-27 20:00 depthai_viewer/log/text.py
+-rw-rw-rw-  2.0 fat     3056 b- defN 24-Apr-27 20:00 depthai_viewer/log/text_internal.py
+-rw-rw-rw-  2.0 fat     5980 b- defN 24-Apr-27 20:00 depthai_viewer/log/transform.py
+-rw-rw-rw-  2.0 fat      910 b- defN 24-Apr-27 20:00 depthai_viewer/log/xlink_stats.py
+-rw-rw-rw-  2.0 fat      175 b- defN 24-Apr-27 20:00 depthai_viewer_bindings/__init__.py
+-rw-rw-rw-  2.0 fat 24340992 b- defN 24-Apr-27 20:00 depthai_viewer_bindings/depthai_viewer_bindings.pyd
+-rw-rw-rw-  2.0 fat     1527 b- defN 24-Apr-27 20:00 depthai_viewer-0.1.9.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       96 b- defN 24-Apr-27 20:00 depthai_viewer-0.1.9.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       62 b- defN 24-Apr-27 20:00 depthai_viewer-0.1.9.dist-info/entry_points.txt
+?rw-rw-r--  2.0 fat     6203 b- defN 24-Apr-27 20:00 depthai_viewer-0.1.9.dist-info/RECORD
+69 files, 24599141 bytes uncompressed, 9824159 bytes compressed:  60.1%
```

## zipnote {}

```diff
@@ -189,20 +189,20 @@
 
 Filename: depthai_viewer_bindings/__init__.py
 Comment: 
 
 Filename: depthai_viewer_bindings/depthai_viewer_bindings.pyd
 Comment: 
 
-Filename: depthai_viewer-0.1.8.dist-info/METADATA
+Filename: depthai_viewer-0.1.9.dist-info/METADATA
 Comment: 
 
-Filename: depthai_viewer-0.1.8.dist-info/WHEEL
+Filename: depthai_viewer-0.1.9.dist-info/WHEEL
 Comment: 
 
-Filename: depthai_viewer-0.1.8.dist-info/entry_points.txt
+Filename: depthai_viewer-0.1.9.dist-info/entry_points.txt
 Comment: 
 
-Filename: depthai_viewer-0.1.8.dist-info/RECORD
+Filename: depthai_viewer-0.1.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## depthai_viewer/install_requirements.py

```diff
@@ -46,15 +46,15 @@
 def download_blobs() -> None:
     import blobconverter
 
     if not os.path.exists(model_dir):
         os.makedirs(model_dir)
     models = {
         "yolov8n_coco_640x352": "depthai",
-        "mobilenet-ssd": "intel",
+        "yolov6nr3_coco_640x352": "depthai",
         "face-detection-retail-0004": "intel",
         "age-gender-recognition-retail-0013": "intel",
         "yolov6n_thermal_people_256x192": "depthai",
     }
     for model, zoo_type in models.items():
         # With use_cache=True, blobconverter will not download / move the blob to model_dir...
         blobconverter.from_zoo(
@@ -87,18 +87,18 @@
             # Install depthai_sdk first, then override depthai version with the one from requirements.txt
             subprocess.run(
                 [
                     venv_python,
                     "-m",
                     "pip",
                     "install",
-                    "depthai-sdk==1.13.1.dev0+b0340e0c4ad869711d7d5fff48e41c46fe41f475",
+                    "depthai-sdk==1.13.1.dev0+dd1a6d8a797107d24b9b91b7b63c3fcffb932712",
                     "--extra-index-url",
                     "https://artifacts.luxonis.com/artifactory/luxonis-python-snapshot-local/",
-                    # "git+https://github.com/luxonis/depthai@develop#subdirectory=depthai_sdk",
+                    # "git+https://github.com/luxonis/depthai@tof_decoding#subdirectory=depthai_sdk",
                 ],
                 check=True,
             )
             subprocess.run(
                 [venv_python, "-m", "pip", "install", "-r", f"{script_path}/requirements.txt"],
                 check=True,
             )
```

## depthai_viewer/requirements.txt

```diff
@@ -1,11 +1,11 @@
 numpy>=1.23
 pyarrow==10.0.1
 setuptools
 ahrs
 # depthai_sdk conflicts with depthai, so it's installed seperatelly in __main__.py
 --extra-index-url https://artifacts.luxonis.com/artifactory/luxonis-python-snapshot-local
-depthai==2.24.0.0.dev0+c014e27e224f7ef3f6407be6b3f05be6c2fffd13
+depthai==2.25.0.0.dev0+dca8245b0b1c52349b73e5a0bf23589b7c4ac3e8
 websockets
 pydantic==1.9
 deprecated
 sentry-sdk
```

## depthai_viewer/_backend/config_api.py

```diff
@@ -7,15 +7,15 @@
 from signal import SIGINT, signal
 from typing import Any, Dict
 
 import depthai as dai
 import websockets
 from websockets.server import WebSocketServerProtocol
 
-from depthai_viewer._backend.device_configuration import PipelineConfiguration
+from depthai_viewer._backend.device_configuration import PipelineConfiguration, ToFConfig
 from depthai_viewer._backend.messages import (
     DevicesMessage,
     ErrorMessage,
     InfoMessage,
     Message,
     MessageType,
 )
@@ -41,14 +41,15 @@
     GET_SUBSCRIPTIONS = auto()
     SET_SUBSCRIPTIONS = auto()
     GET_PIPELINE = auto()
     SET_FLOOD_BRIGHTNESS = auto()
     SET_DOT_BRIGHTNESS = auto()
     RESET = auto()  # When anything bad happens, a reset occurs (like closing ws connection)
     GET_AVAILABLE_DEVICES = auto()
+    SET_TOF_CONFIG = auto()
 
 
 def dispatch_action(action: Action, **kwargs) -> Message:  # type: ignore[no-untyped-def]
     """
     Dispatches an action that will be executed by main.py.
 
     Returns: Message that will be sent to the frontend
@@ -137,14 +138,31 @@
             elif message_type == MessageType.SET_DOT_BRIGHTNESS:
                 data = message.get("data", {})
                 dot_brightness = data.get(message_type, None)
                 if dot_brightness is None:
                     print("Missing dot", message_type)
                     continue
                 await send_message(websocket, dispatch_action(Action.SET_DOT_BRIGHTNESS, dot_brightness=dot_brightness))
+            elif message_type == MessageType.SET_TOF_CONFIG:
+                data = message.get("data", {})
+                tof_config = data.get(message_type, None)
+                if len(tof_config) == 2:  # Disregard the camera board socket for now. Only support one.
+                    tof_config = tof_config[1]
+                else:
+                    print("Invalid tof config: ", tof_config)
+                    continue
+                if tof_config is None:
+                    print("Missing tof config")
+                    continue
+                try:
+                    tof_config = ToFConfig(**tof_config)
+                except Exception as e:
+                    print(f"Failed to deserialize tof_config: {tof_config}: {e}")
+                    continue
+                await send_message(websocket, dispatch_action(Action.SET_TOF_CONFIG, tof_config=tof_config))
             else:
                 print("Unknown message type: ", message_type)
                 continue
 
         message_to_send = None
         try:
             message_to_send = send_message_queue.get(timeout=0.01)
```

## depthai_viewer/_backend/device.py

```diff
@@ -6,45 +6,48 @@
 from typing import Dict, List, Optional, Tuple
 
 import depthai as dai
 import numpy as np
 from depthai_sdk import OakCamera
 from depthai_sdk.classes.packet_handlers import ComponentOutput
 from depthai_sdk.components import CameraComponent, NNComponent, StereoComponent
-from depthai_sdk.components.camera_helper import (
-    getClosestIspScale,
-)
-from depthai_sdk.components.tof_component import Component
+from depthai_sdk.components.camera_helper import getClosestIspScale
+from depthai_sdk.components.tof_component import Component, ToFComponent
 from numpy.typing import NDArray
 
 import depthai_viewer as viewer
 from depthai_viewer._backend.device_configuration import (
     ALL_NEURAL_NETWORKS,
     CameraConfiguration,
     CameraFeatures,
     CameraSensorResolution,
     DeviceInfo,
     DeviceProperties,
     ImuKind,
     PipelineConfiguration,
     StereoDepthConfiguration,
+    ToFConfig,
     XLinkConnection,
     calculate_isp_scale,
     compare_dai_camera_configs,
     get_size_from_resolution,
     size_to_resolution,
 )
 from depthai_viewer._backend.device_defaults import oak_t_default
 from depthai_viewer._backend.messages import (
     ErrorMessage,
     InfoMessage,
     Message,
     WarningMessage,
 )
-from depthai_viewer._backend.packet_handler import DetectionContext, PacketHandler, PacketHandlerContext
+from depthai_viewer._backend.packet_handler import (
+    DetectionContext,
+    PacketHandler,
+    PacketHandlerContext,
+)
 from depthai_viewer._backend.store import Store
 from depthai_viewer.install_requirements import model_dir
 
 
 class XlinkStatistics:
     _device: dai.Device
     _time_of_last_update: float = 0  # s since epoch
@@ -81,14 +84,15 @@
     _stereo: StereoComponent = None
     _nnet: NNComponent = None
     _xlink_statistics: Optional[XlinkStatistics] = None
     _sys_info_q: Optional[Queue] = None  # type: ignore[type-arg]
     _pipeline_start_t: Optional[float] = None
     _queues: List[Tuple[Component, ComponentOutput]] = []
     _dai_queues: List[Tuple[dai.Node, dai.DataOutputQueue, Optional[PacketHandlerContext]]] = []
+    _tof_component: Optional[ToFComponent] = None
 
     # _profiler = cProfile.Profile()
 
     def __init__(self, device_id: str, store: Store):
         self.id = device_id
         self.set_oak(OakCamera(device_id, args={"irFloodBrightness": 0, "irDotBrightness": 0}))
         self.store = store
@@ -107,17 +111,22 @@
         return self._oak is not None and self._oak.device.isClosed()
 
     def get_intrinsic_matrix(self, board_socket: dai.CameraBoardSocket, width: int, height: int) -> NDArray[np.float32]:
         if self.intrinsic_matrix.get((board_socket, width, height)) is not None:
             return self.intrinsic_matrix.get((board_socket, width, height))  # type: ignore[return-value]
         if self.calibration_data is None:
             raise Exception("Missing calibration data!")
-        M_right = self.calibration_data.getCameraIntrinsics(  # type: ignore[union-attr]
-            board_socket, dai.Size2f(width, height)
-        )
+        try:
+            M_right = self.calibration_data.getCameraIntrinsics(  # type: ignore[union-attr]
+                board_socket, dai.Size2f(width, height)
+            )
+        except RuntimeError:
+            print("No intrinsics found for camera: ", board_socket, " assuming default.")
+            f_len = (height * width) ** 0.5
+            M_right = [[f_len, 0, width / 2], [0, f_len, height / 2], [0, 0, 1]]
         self.intrinsic_matrix[(board_socket, width, height)] = np.array(M_right).reshape(3, 3)
         return self.intrinsic_matrix[(board_socket, width, height)]
 
     def _get_possible_stereo_pairs_for_cam(
         self, cam: dai.CameraFeatures, connected_camera_features: List[dai.CameraFeatures]
     ) -> List[dai.CameraBoardSocket]:
         """Tries to find the possible stereo pairs for a camera."""
@@ -224,14 +233,15 @@
                 CameraFeatures(
                     board_socket=cam.socket,
                     max_fps=60,
                     resolutions=all_supported_resolutions,
                     supported_types=cam.supportedTypes,
                     stereo_pairs=self._get_possible_stereo_pairs_for_cam(cam, connected_cam_features),
                     name=cam.name.capitalize(),
+                    tof_config=ToFConfig() if dai.CameraSensorType.TOF in cam.supportedTypes else None,
                 )
             )
         device_properties.stereo_pairs = list(
             itertools.chain.from_iterable(
                 [(cam.board_socket, pair) for pair in cam.stereo_pairs] for cam in device_properties.cameras
             )
         )
@@ -326,37 +336,37 @@
         # 2. Create stereo depth
         if not has_tof:
             try:
                 calibration = self._oak.device.readCalibration2()
                 left_cam = calibration.getStereoLeftCameraId()
                 right_cam = calibration.getStereoRightCameraId()
                 if left_cam.value != 255 and right_cam.value != 255:
-                    config.depth = StereoDepthConfiguration(
+                    config.stereo = StereoDepthConfiguration(
                         stereo_pair=(left_cam, right_cam),
                         align=rgb_cam_socket if rgb_cam_socket is not None else left_cam,
                     )
             except RuntimeError:
                 calibration = None
         else:
-            config.depth = None
+            config.stereo = None
         # 3. Create YOLO
         nnet_cam_sock = rgb_cam_socket
         if nnet_cam_sock is None:
             # Try to find a color camera config
             nnet_cam_sock = next(
                 filter(
                     lambda cam: cam.kind == dai.CameraSensorType.COLOR,  # type: ignore[arg-type,union-attr]
                     config.cameras,
                 ),
                 None,
             )  # type: ignore[assignment]
             if nnet_cam_sock is not None:
                 nnet_cam_sock = nnet_cam_sock.board_socket
         if nnet_cam_sock is not None:
-            config.ai_model = ALL_NEURAL_NETWORKS[1]  # Mobilenet SSd
+            config.ai_model = ALL_NEURAL_NETWORKS[1]  # Yolo V6
             config.ai_model.camera = nnet_cam_sock
         else:
             config.ai_model = ALL_NEURAL_NETWORKS[1]
         return InfoMessage("Created auto pipeline config")
 
     def update_pipeline(self, runtime_only: bool) -> Message:
         if self._oak is None:
@@ -364,16 +374,16 @@
 
         config = self.store.pipeline_config
         if config is None:
             return ErrorMessage("No pipeline config, can't update pipeline!")
 
         if self._oak.device.isPipelineRunning():
             if runtime_only:
-                if config.depth is not None:
-                    self._stereo.control.send_controls(config.depth.to_runtime_controls())
+                if config.stereo is not None:
+                    self._stereo.control.send_controls(config.stereo.to_runtime_controls())
                     return InfoMessage("")
                 return ErrorMessage("Depth is disabled, can't send runtime controls!")
             print("Cam running, closing...")
             self.close_oak()
             message = self.reconnect_to_oak()
             if isinstance(message, ErrorMessage):
                 return message
@@ -435,24 +445,25 @@
             if not does_sensor_support_resolution:
                 smallest_supported_resolution = [
                     config for config in camera_features.configs if config.type == camera_features.supportedTypes[0]
                 ][0]
                 sensor_resolution = size_to_resolution.get(
                     (smallest_supported_resolution.width, smallest_supported_resolution.height), None
                 )
-            is_used_by_depth = config.depth is not None and (
-                cam.board_socket == config.depth.align or cam.board_socket in config.depth.stereo_pair
+            is_used_by_depth = config.stereo is not None and (
+                cam.board_socket == config.stereo.align or cam.board_socket in config.stereo.stereo_pair
             )
             is_used_by_ai = config.ai_model is not None and cam.board_socket == config.ai_model.camera
             cam.stream_enabled |= is_used_by_depth or is_used_by_ai
 
             # Only create a camera node if it is used by stereo or AI.
             if cam.stream_enabled:
                 if dai.CameraSensorType.TOF in camera_features.supportedTypes:
                     sdk_cam = self._oak.create_tof(cam.board_socket)
+                    self._tof_component = sdk_cam
                     self._queues.append((sdk_cam, self._oak.queue(sdk_cam.out.main)))
                 elif dai.CameraSensorType.THERMAL in camera_features.supportedTypes:
                     thermal_cam = self._oak.pipeline.create(dai.node.Camera)
                     # Hardcoded for OAK-T. The correct size is needed for correct detection parsing
                     thermal_cam.setSize(256, 192)
                     thermal_cam.setBoardSocket(cam.board_socket)
                     xout_thermal = self._oak.pipeline.create(dai.node.XLinkOut)
@@ -474,45 +485,45 @@
                             )
                         )
                     self._queues.append((sdk_cam, self._oak.queue(sdk_cam.out.main)))
                 else:
                     print("Skipped creating camera:", cam.board_socket, "because no valid sensor resolution was found.")
                     continue
 
-        if config.depth:
+        if config.stereo:
             print("Creating depth")
-            stereo_pair = config.depth.stereo_pair
+            stereo_pair = config.stereo.stereo_pair
             left_cam = self._get_component_by_socket(stereo_pair[0])
             right_cam = self._get_component_by_socket(stereo_pair[1])
             if not left_cam or not right_cam:
                 return ErrorMessage(f"{cam} is not configured. Couldn't create stereo pair.")
 
             if left_cam.node.getResolutionWidth() > 1280:
                 print("Left cam width > 1280, setting isp scale to get 800")
                 left_cam.config_color_camera(isp_scale=calculate_isp_scale(left_cam.node.getResolutionWidth()))
             if right_cam.node.getResolutionWidth() > 1280:
                 print("Right cam width > 1280, setting isp scale to get 800")
                 right_cam.config_color_camera(isp_scale=calculate_isp_scale(right_cam.node.getResolutionWidth()))
             self._stereo = self._oak.create_stereo(left=left_cam, right=right_cam, name="depth")
 
-            align_component = self._get_component_by_socket(config.depth.align)
+            align_component = self._get_component_by_socket(config.stereo.align)
             if not align_component:
-                return ErrorMessage(f"{config.depth.align} is not configured. Couldn't create stereo pair.")
+                return ErrorMessage(f"{config.stereo.align} is not configured. Couldn't create stereo pair.")
             self._stereo.config_stereo(
-                lr_check=config.depth.lr_check,
-                subpixel=config.depth.subpixel_disparity,
-                confidence=config.depth.confidence,
+                lr_check=config.stereo.lr_check,
+                subpixel=config.stereo.subpixel_disparity,
+                confidence=config.stereo.confidence,
                 align=align_component,
-                lr_check_threshold=config.depth.lrc_threshold,
-                median=config.depth.median,
+                lr_check_threshold=config.stereo.lrc_threshold,
+                median=config.stereo.median,
             )
 
-            aligned_camera = self._get_camera_config_by_socket(config, config.depth.align)
+            aligned_camera = self._get_camera_config_by_socket(config, config.stereo.align)
             if not aligned_camera:
-                return ErrorMessage(f"{config.depth.align} is not configured. Couldn't create stereo pair.")
+                return ErrorMessage(f"{config.stereo.align} is not configured. Couldn't create stereo pair.")
             self._queues.append((self._stereo, self._oak.queue(self._stereo.out.main)))
 
         if self._oak.device.getConnectedIMU() != "NONE" and self._oak.device.getConnectedIMU() != "":
             print("Creating IMU, connected IMU: ", self._oak.device.getConnectedIMU())
             # TODO(someone): Handle IMU updates
             imu = self._oak.create_imu()
             sensors = [
@@ -568,15 +579,15 @@
                     ),
                 )
             elif not cam_component:
                 self.store.send_message_to_frontend(
                     WarningMessage(f"{config.ai_model.camera} is not configured, won't create NNET.")
                 )
             elif config.ai_model.path == "age-gender-recognition-retail-0013":
-                face_detection = self._oak.create_nn(model_path, cam_component)
+                face_detection = self._oak.create_nn("face-detection-retail-0004", cam_component)
                 self._nnet = self._oak.create_nn(model_path, input=face_detection)
             else:
                 self._nnet = self._oak.create_nn(model_path, cam_component)
             if self._nnet:
                 self._queues.append((self._nnet, self._oak.queue(self._nnet.out.main)))
 
         sys_logger_xlink = self._oak.pipeline.createXLinkOut()
@@ -639,14 +650,17 @@
         # if time.time() - self.start > 10:
         #     print("Dumping profiling data")
         #     self._profiler.dump_stats("profile.prof")
         #     self._profiler.disable()
         #     self._profiler.enable()
         #     self.start = time.time()
 
+    def get_tof_component(self) -> Optional[ToFComponent]:
+        return self._tof_component
+
 
 def print_system_information(info: dai.SystemInformation) -> None:
     print(
         "Ddr used / total - %.2f / %.2f MiB"
         % (
             info.ddrMemoryUsage.used / (1024.0 * 1024.0),
             info.ddrMemoryUsage.total / (1024.0 * 1024.0),
```

## depthai_viewer/_backend/device_configuration.py

```diff
@@ -85,16 +85,16 @@
 
     @property
     def out_queue_name(self) -> str:
         return str(QueueNames.depthRaw.name)
 
 
 class AiModelConfiguration(BaseModel):  # type: ignore[misc]
-    display_name: str = "MobileNet SSD"
-    path: str = "mobilenet-ssd"
+    display_name: str = "Yolo V6"
+    path: str = "yolov6nr3_coco_640x352"
     camera: dai.CameraBoardSocket
 
     class Config:
         arbitrary_types_allowed = True
 
     def __init__(self, **v) -> None:  # type: ignore[no-untyped-def]
         if v.get("camera", None) and isinstance(v["camera"], str):
@@ -112,16 +112,16 @@
 ALL_NEURAL_NETWORKS = [
     AiModelConfiguration(
         path="yolov8n_coco_640x352",
         display_name="Yolo V8",
         camera=dai.CameraBoardSocket.CAM_A,
     ),
     AiModelConfiguration(
-        path="mobilenet-ssd",
-        display_name="MobileNet SSD",
+        path="yolov6nr3_coco_640x352",
+        display_name="Yolo V6",
         camera=dai.CameraBoardSocket.CAM_A,
     ),
     AiModelConfiguration(
         path="face-detection-retail-0004",
         display_name="Face Detection",
         camera=dai.CameraBoardSocket.CAM_A,
     ),
@@ -226,42 +226,88 @@
         if not kwargs.get("kind", None):
             kwargs["kind"] = dai.CameraSensorType.COLOR
         if not kwargs.get("resolution", None):
             kwargs["resolution"] = CameraSensorResolution.THE_720_P
         return cls(board_socket="RGB", **kwargs)
 
 
+class ToFConfig(BaseModel):  # type: ignore[misc]
+    median: Optional[dai.MedianFilter] = dai.MedianFilter.MEDIAN_OFF
+    phase_unwrapping_level: int = 4
+    phase_unwrap_error_threshold: int = 100
+    enable_phase_unwrapping: Optional[bool] = True
+    enable_fppn_correction: Optional[bool] = None
+    enable_optical_correction: Optional[bool] = None
+    enable_temperature_correction: Optional[bool] = None
+    enable_wiggle_correction: Optional[bool] = None
+
+    class Config:
+        arbitrary_types_allowed = True
+
+    def __init__(self, **v) -> None:  # type: ignore[no-untyped-def]
+        if v.get("median", None):
+            if isinstance(v["median"], str):
+                v["median"] = getattr(dai.MedianFilter, v["median"])
+        return super().__init__(**v)  # type: ignore[no-any-return]
+
+    def dict(self, *args, **kwargs) -> Dict[str, Any]:  # type: ignore[no-untyped-def]
+        return {
+            "median": self.median.name if self.median else None,
+            "phase_unwrapping_level": self.phase_unwrapping_level,
+            "phase_unwrap_error_threshold": self.phase_unwrap_error_threshold,
+            "enable_fppn_correction": self.enable_fppn_correction,
+            "enable_optical_correction": self.enable_optical_correction,
+            "enable_temperature_correction": self.enable_temperature_correction,
+            "enable_wiggle_correction": self.enable_wiggle_correction,
+            "enable_phase_unwrapping": self.enable_phase_unwrapping,
+        }
+
+    def to_dai(self) -> dai.RawToFConfig:
+        cfg = dai.RawToFConfig()
+        cfg.median = self.median  # type: ignore[attr-defined]
+        cfg.phaseUnwrappingLevel = self.phase_unwrapping_level  # type: ignore[attr-defined]
+        cfg.phaseUnwrapErrorThreshold = self.phase_unwrap_error_threshold  # type: ignore[attr-defined]
+        cfg.enableFPPNCorrection = self.enable_fppn_correction  # type: ignore[attr-defined]
+        cfg.enableOpticalCorrection = self.enable_optical_correction  # type: ignore[attr-defined]
+        cfg.enableTemperatureCorrection = self.enable_temperature_correction  # type: ignore[attr-defined]
+        cfg.enableWiggleCorrection = self.enable_wiggle_correction  # type: ignore[attr-defined]
+        cfg.enablePhaseUnwrapping = self.enable_phase_unwrapping  # type: ignore[attr-defined]
+        return cfg
+
+
 class CameraFeatures(BaseModel):  # type: ignore[misc]
     resolutions: List[CameraSensorResolution] = []
     max_fps: int = 60
     board_socket: dai.CameraBoardSocket
     supported_types: List[dai.CameraSensorType]
     stereo_pairs: List[dai.CameraBoardSocket] = []
     """Which cameras can be paired with this one"""
     name: str
+    tof_config: Optional[ToFConfig] = None
 
     class Config:
         arbitrary_types_allowed = True
         use_enum_values = True
 
     def dict(self, *args, **kwargs) -> Dict[str, Any]:  # type: ignore[no-untyped-def]
         return {
             "resolutions": [r for r in self.resolutions],
             "max_fps": self.max_fps,
             "board_socket": self.board_socket.name,
             "supported_types": [sensor_type.name for sensor_type in self.supported_types],
             "stereo_pairs": [socket.name for socket in self.stereo_pairs],
             "name": self.name,
+            "tof_config": self.tof_config.dict() if self.tof_config else None,
         }
 
 
 class PipelineConfiguration(BaseModel):  # type: ignore[misc]
     auto: bool = False  # Should the backend automatically create a pipeline?
     cameras: List[CameraConfiguration] = []
-    depth: Optional[StereoDepthConfiguration]
+    stereo: Optional[StereoDepthConfiguration]
     ai_model: Optional[AiModelConfiguration]
     imu: ImuConfiguration = ImuConfiguration()
 
 
 class XLinkConnection(Enum):
     USB = "Usb"
     POE = "PoE"
```

## depthai_viewer/_backend/main.py

```diff
@@ -143,14 +143,23 @@
         elif action == Action.SET_DOT_BRIGHTNESS:
             print("Set dot: ", kwargs.get("dot_brightness", 0))
             self.store.set_dot_brightness(kwargs.get("dot_brightness", 0))
             if self._device and self._device._oak:
                 self._device._oak.device.setIrLaserDotProjectorBrightness(self.store.dot_brightness)
                 return InfoMessage("Dot projector set successfully")
             return ErrorMessage("No device selected")
+        elif action == Action.SET_TOF_CONFIG:
+            if self._device and self._device._oak:
+                if tof_component := self._device.get_tof_component():
+                    if tof_config := kwargs.get("tof_config", None):
+                        tof_component.control.send_controls(tof_config.to_dai())
+                        return InfoMessage("ToF config updated successfully")
+                    return ErrorMessage("ToF config not provided")
+                return ErrorMessage("Failed to update ToF config. ToF node wasn't found.")
+            return ErrorMessage("No device selected")
         return ErrorMessage(f"Action: {action} not implemented")
 
     def run(self) -> None:
         """Handles ws messages and polls OakCam."""
         while True:
             try:
                 action, kwargs = self.action_queue.get(timeout=0.0001)
```

## depthai_viewer/_backend/messages.py

```diff
@@ -10,14 +10,15 @@
 class MessageType:
     SUBSCRIPTIONS = "Subscriptions"  # Get or set subscriptions
     PIPELINE = "Pipeline"  # Get or Set pipeline
     DEVICES = "Devices"  # Get device list
     DEVICE = "DeviceProperties"  # Get or set device
     SET_FLOOD_BRIGHTNESS = "SetFloodBrightness"  # Set floodlight
     SET_DOT_BRIGHTNESS = "SetDotBrightness"  # Set floodlight
+    SET_TOF_CONFIG = "SetToFConfig"  # Set ToF config
     ERROR = "Error"  # Error message
     INFO = "Info"  # Info message
     WARNING = "Warning"  # Warning message
 
 
 class ErrorAction(Enum):
     NONE = "None"
```

## depthai_viewer/_backend/packet_handler.py

```diff
@@ -2,22 +2,29 @@
 
 import cv2
 import depthai as dai
 import numpy as np
 from ahrs.filters import Mahony
 from depthai_sdk.classes.packets import (  # PointcloudPacket,
     BasePacket,
+    BoundingBox,
     DepthPacket,
+    Detection,
     DetectionPacket,
     DisparityDepthPacket,
     FramePacket,
     IMUPacket,
     TwoStagePacket,
 )
-from depthai_sdk.components import CameraComponent, Component, NNComponent, StereoComponent
+from depthai_sdk.components import (
+    CameraComponent,
+    Component,
+    NNComponent,
+    StereoComponent,
+)
 from depthai_sdk.components.tof_component import ToFComponent
 from numpy.typing import NDArray
 from pydantic import BaseModel
 
 import depthai_viewer as viewer
 from depthai_viewer._backend.store import Store
 from depthai_viewer._backend.topic import Topic
@@ -194,15 +201,15 @@
             return
         viewer.log_imu([accel.z, accel.x, accel.y], [gyro.z, gyro.x, gyro.y], self._ahrs.Q, [mag.x, mag.y, mag.z])
 
     def _on_stereo_frame(self, packet: Union[DepthPacket, DisparityDepthPacket], component: StereoComponent) -> None:
         depth_frame = packet.frame
         cam = "color_cam" if component._align_component.is_color() else "mono_cam"
         path = f"{component._align_component._socket.name}/transform/{cam}" + "/Depth"
-        if not self.store.pipeline_config or not self.store.pipeline_config.depth:
+        if not self.store.pipeline_config or not self.store.pipeline_config.stereo:
             # Essentially impossible to get here
             return
         viewer.log_depth_image(path, depth_frame, meter=1e3)
 
     def _on_tof_packet(
         self,
         packet: DisparityDepthPacket,
@@ -230,23 +237,35 @@
             f"{component._get_camera_comp()._socket.name}/transform/{cam}/Detections",
             rects,
             rect_format=RectFormat.XYXY,
             colors=colors,
             labels=labels,
         )
 
+    def _rect_from_sdk_detection(
+        self, packet_bbox: BoundingBox, detection: Detection, max_height: int, max_width: int
+    ) -> List[int]:
+        bbox = packet_bbox.get_relative_bbox(detection.bbox)
+        (x1, y1), (x2, y2) = bbox.denormalize((max_height, max_width))
+        return [
+            max(x1, 0),
+            max(y1, 0),
+            min(x2, max_width),
+            min(y2, max_height),
+        ]
+
     def _detections_to_rects_colors_labels(
         self, packet: DetectionPacket, omz_labels: Optional[List[str]] = None
     ) -> Tuple[List[List[int]], List[List[int]], List[str]]:
         rects = []
         colors = []
         labels = []
         for detection in packet.detections:
             rects.append(
-                self._rect_from_detection(detection.img_detection, packet.frame.shape[0], packet.frame.shape[1])
+                self._rect_from_sdk_detection(packet.bbox, detection, packet.frame.shape[0], packet.frame.shape[1])
             )
             colors.append([0, 255, 0])
             label: str = detection.label_str
             # Open model zoo models output label index
             if omz_labels is not None and isinstance(label, int):
                 label += omz_labels[label]
             label += ", " + str(int(detection.img_detection.confidence * 100)) + "%"
@@ -261,15 +280,15 @@
             label = f"{gender_str}, {age}"
             color = [255, 0, 0] if gender[0] > gender[1] else [0, 0, 255]
             # TODO(filip): maybe use viewer.log_annotation_context to log class colors for detections
 
             cam = "color_cam" if component._get_camera_comp().is_color() else "mono_cam"
             viewer.log_rect(
                 f"{component._get_camera_comp()._socket.name}/transform/{cam}/Detection",
-                self._rect_from_detection(det.img_detection, packet.frame.shape[0], packet.frame.shape[1]),
+                self._rect_from_sdk_detection(packet.bbox, det, packet.frame.shape[0], packet.frame.shape[1]),
                 rect_format=RectFormat.XYXY,
                 color=color,
                 label=label,
             )
 
     def _rect_from_detection(self, detection: dai.ImgDetection, max_height: int, max_width: int) -> List[int]:
         return [
```

## Comparing `depthai_viewer-0.1.8.dist-info/METADATA` & `depthai_viewer-0.1.9.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: depthai-viewer
-Version: 0.1.8
+Version: 0.1.9
 Classifier: Programming Language :: Rust
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Classifier: Programming Language :: Python :: Implementation :: PyPy
 Classifier: Development Status :: 3 - Alpha
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Classifier: Topic :: Scientific/Engineering :: Visualization
 Requires-Dist: deprecated
@@ -15,17 +15,17 @@
 Provides-Extra: tests
 Summary: Depthai Viewer
 Keywords: computer-vision,logging,depthai-viewer
 Author-email: Luxonis <filip.jeretina@luxonis.com>
 License: MIT OR Apache-2.0
 Requires-Python: >=3.8
 Description-Content-Type: text/markdown; charset=UTF-8; variant=GFM
-Project-URL: repository, https://github.com/luxonis/depthai-viewer
 Project-URL: documentation, https://www.rerun.io/docs
 Project-URL: homepage, https://www.rerun.io
+Project-URL: repository, https://github.com/luxonis/depthai-viewer
 
 # Depthai Viewer
 ![depthai-viewer](https://github.com/luxonis/depthai-viewer/assets/59307111/6a03d8a0-6a70-41d3-b263-15ee279a02aa)
 
 ![Screenshot from 2023-05-20 00-22-36](https://user-images.githubusercontent.com/59307111/248265850-781476ac-2082-45ad-861b-157fa708abf0.png)
 
 ## Install
```

## Comparing `depthai_viewer-0.1.8.dist-info/RECORD` & `depthai_viewer-0.1.9.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 depthai_viewer/__init__.py,sha256=GgNb48PoLotyHGZ9QF497Y8Xl3fBIFqzPQ0DZ_h7oT4,17989
 depthai_viewer/__main__.py,sha256=CsvfSdQmL0UsMdzLE5sKrJqfUBTUPnXn8N0QMmuEtxg,953
 depthai_viewer/color_conversion.py,sha256=IDRKG9gnrBiMqEHVILzNf-lD1_v4IX6bRA5CgAxX-1s,2956
-depthai_viewer/install_requirements.py,sha256=UOUNojPDaOz5GaL2x6c0-AXe-Ht0KFXjI5SOpPDQofQ,5673
+depthai_viewer/install_requirements.py,sha256=gCTfW09Vw8kJsb2DwEY95nXQ7HiPVUJ_zRkEZzDjZPA,5689
 depthai_viewer/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 depthai_viewer/recording.py,sha256=nh4j-lmD5sSgESHuBSYvpKX-MqDvDmd97lDbUFqZQCo,5016
-depthai_viewer/requirements.txt,sha256=vt1qmPIS3Y2L3QYtmH1JEILqEe8MjN37mFeqMIim1JI,339
+depthai_viewer/requirements.txt,sha256=vU1xkCljRkLF-UDFJB0FfaNZH3ywS-fAhdYl0y18mUA,339
 depthai_viewer/script_helpers.py,sha256=aTMnsWawHE1jzMmtiBopAG885pA5LnJXSKKrbKDrFdM,2666
 depthai_viewer/_backend/.gitignore,sha256=mTydNaQHG9xBvOhZR-aBh11GGHj0Xft55Fk2o2KstEI,61
 depthai_viewer/_backend/README.md,sha256=uJEGTc7RWhc3LMXTKbSuiVTLcJXf6G84GVdb8tiGNlQ,992
 depthai_viewer/_backend/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 depthai_viewer/_backend/classification_labels.py,sha256=_GpS83tqWDky138-Bre0_P2r20WHTQAE6jDegrXXZhw,336
-depthai_viewer/_backend/config_api.py,sha256=EvoHnJQLLFTAB8e_-Z4_kzF8S4XKR_xj8dY7PXauRGg,7264
+depthai_viewer/_backend/config_api.py,sha256=WvskBl91y226qHb15tbD3Nx3CTu5qNwsvwk-FB4Gtn0,8205
 depthai_viewer/_backend/depth.py,sha256=FDvATh8YEL-0-JI_UeIx4tuzvrtW1fqAOIekXAF2okc,3367
-depthai_viewer/_backend/device.py,sha256=AKHADhuCHveCcLwbjg-ZOvfxXP7T4tKvfnEejWkMVEQ,31193
-depthai_viewer/_backend/device_configuration.py,sha256=vtlyaYplJ4czrmWXIgvAmxI-YAngHNqZbH7QTz5UKqk,13442
-depthai_viewer/_backend/main.py,sha256=0i3XumMFHuqQVYy-411SfGkTGfIxXsMnmRArAmMEI38,8313
-depthai_viewer/_backend/messages.py,sha256=ZlIxXgqDO0rBR_WbCqOAW_DtARoABLexIVYka1S8M5k,3726
-depthai_viewer/_backend/packet_handler.py,sha256=iqDjBbp73xhtgD6VAtl5YgXTOStls00_MqBnwKnIH50,13036
+depthai_viewer/_backend/device.py,sha256=zDIGM46R_51XSwo-bRLcEB0kYsGj-pObFcwrrbuy0k4,31842
+depthai_viewer/_backend/device_configuration.py,sha256=W1CE870oy1yDJmT7fFo5uy7Kd6e2rwFK6s7dARW75kw,15958
+depthai_viewer/_backend/main.py,sha256=T-ScvLHdllXtKOntKbb7PpI36ttP0p4g3u3SByWCtbo,8929
+depthai_viewer/_backend/messages.py,sha256=yYWYobUvIm9t8j8c8TdXqdGhqNI4dHJ5xtYcyydyXZg,3781
+depthai_viewer/_backend/packet_handler.py,sha256=6ZLDUpIkFbtA9Z9rILExpE_e61EWO8snI9eXZjzuhMI,13536
 depthai_viewer/_backend/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 depthai_viewer/_backend/store.py,sha256=5cTGF5_dC7ACkM4uEjB0cce9Up9xsnXbNyOA8OmMuAU,1778
 depthai_viewer/_backend/topic.py,sha256=dKjImtPN3qBgulX0fnWkc4ZAoB8qw2ijBEBKG4ZQcDE,609
 depthai_viewer/_backend/device_defaults/oak_t_default.py,sha256=Ld0TGdTQ0SPBaVy7zHtUncouo1xYI3uMIzTSccbYeNU,959
 depthai_viewer/components/__init__.py,sha256=Tw1eXJ8Q5NOuMp6sX-9NJJ_4sKHNEIjJF5EqaImQ59k,2884
 depthai_viewer/components/annotation.py,sha256=nVAlr1lI316KdSXTtKXzhGXrX3Eq85rdRNFdUppty8k,1614
 depthai_viewer/components/arrow.py,sha256=b7tAvMTEzviCJdRfQTCBWLibXcibSr55QcMaOPa2HtE,1243
@@ -58,12 +58,12 @@
 depthai_viewer/log/scalar.py,sha256=7rKY7dOuxA_BZYXBUoKSaP3s65XtyF7vRorokyGVZ4w,5835
 depthai_viewer/log/tensor.py,sha256=m7L15EBtj12J2ozkUu5Mx_3O-DQb6JkdwuYDMiyuv5s,4389
 depthai_viewer/log/text.py,sha256=FXljKcAgcnsBivOWPAq6Z0SeM70bn4SHj5X-q0ylQ_Y,4354
 depthai_viewer/log/text_internal.py,sha256=0i4U6nRb6VmPv7r3CSl0brthg0S3VOHPYlRk0NPuWBI,3056
 depthai_viewer/log/transform.py,sha256=P_YFbtY0l59FOHmEdtlSSbEiRnrTNNsfuHPLyyvlH9o,5980
 depthai_viewer/log/xlink_stats.py,sha256=a7zJzlGWeo6wtOWpINuxR2k8j5WC2E6wqLm8djrkUM4,910
 depthai_viewer_bindings/__init__.py,sha256=J1n5uGnCv7uT49bgmOMRsVTse6lSw3bWsuf0bNBNAUA,175
-depthai_viewer_bindings/depthai_viewer_bindings.pyd,sha256=bu8eAAuhZj3fVLPBBCZkF_17hOHV5l778V7-bE25UA0,24456192
-depthai_viewer-0.1.8.dist-info/METADATA,sha256=zvC7khdUipisCWUtREZBbCeHypLCoSAT09kQmUP8Ybw,1527
-depthai_viewer-0.1.8.dist-info/WHEEL,sha256=KlEdRPk785weBBgoPUt2hPXb_NEUecMNdyoRfZuW1Yk,96
-depthai_viewer-0.1.8.dist-info/entry_points.txt,sha256=A6MbC2hpgRzxBLH3M5MYqx6WylT7-y7VWuw78W05bzA,62
-depthai_viewer-0.1.8.dist-info/RECORD,,
+depthai_viewer_bindings/depthai_viewer_bindings.pyd,sha256=KznjE6VS3ZxR67zkSl5ecCwX9Dl3nMchPmx1Sed4ra0,24340992
+depthai_viewer-0.1.9.dist-info/METADATA,sha256=kiet5vJQlC7ZDk3a_SzGGfRAgv9ALWDMfaPC4ofNDvQ,1527
+depthai_viewer-0.1.9.dist-info/WHEEL,sha256=KlEdRPk785weBBgoPUt2hPXb_NEUecMNdyoRfZuW1Yk,96
+depthai_viewer-0.1.9.dist-info/entry_points.txt,sha256=A6MbC2hpgRzxBLH3M5MYqx6WylT7-y7VWuw78W05bzA,62
+depthai_viewer-0.1.9.dist-info/RECORD,,
```

